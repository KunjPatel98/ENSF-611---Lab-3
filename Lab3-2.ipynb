{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87fee377",
   "metadata": {},
   "source": [
    "# Lab 3 - Part 2: PCA and Clustering (12 marks)\n",
    "### Due Date: Monday, March 13 at 12pm\n",
    "\n",
    "Author: *Kunj Patel*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f05d0",
   "metadata": {},
   "source": [
    "The purpose of this portion of the assignment is to practice using PCA and clustering techniques on a given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4299ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a83b6f",
   "metadata": {},
   "source": [
    "## 0. Function definitions (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d602f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def cluster_fn(n_clusters, X, n_components=0):\n",
    "    '''Calculate silhouette score for a given dataset, number of clusters, \n",
    "       and number of principle components using Kmeans clustering (random_state=0)\n",
    "        \n",
    "        n_clusters (int): number of clusters to use for Kmeans\n",
    "        X (numpy.array or pandas.DataFrame): unlabelled dataset\n",
    "        n_components (int): number of principle components (optional)\n",
    "        \n",
    "        returns: silhouette score\n",
    "    \n",
    "    '''\n",
    "    # Apply PCA to reduce dimensionality if n_components is provided\n",
    "    if n_components > 0:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X = pca.fit_transform(X)\n",
    "    \n",
    "    # Cluster the data using KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    # Calculate the silhouette score\n",
    "    score = silhouette_score(X, labels)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7cfa4f",
   "metadata": {},
   "source": [
    "## 1. Load data (2 marks)\n",
    "\n",
    "For this assignment, we will use the dataset found below:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Chemical+Composition+of+Ceramic+Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474481f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Chemical Composion of Ceramic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908b657",
   "metadata": {},
   "source": [
    "Two of the columns are non-numeric. For this assignment, we will remove those two columns and focus on clustering the ceramic samples based on the numerical measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2efda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove non-numeric columns\n",
    "# Select only numeric columns\n",
    "\n",
    "df = df.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf578b1",
   "metadata": {},
   "source": [
    "## 2. Implement clustering (8 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c62e1",
   "metadata": {},
   "source": [
    "### 2.1 Cluster using raw data (1 mark)\n",
    "\n",
    "Implement Kmeans clustering using the raw data. Compare the silhouette scores using 2, 3, 4, 5 and 6 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f85da0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for 2 clusters: 0.584\n",
      "Silhouette score for 3 clusters: 0.562\n",
      "Silhouette score for 4 clusters: 0.543\n",
      "Silhouette score for 5 clusters: 0.508\n",
      "Silhouette score for 6 clusters: 0.510\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement clustering with raw data using cluster_fn above\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Get the raw data\n",
    "X = df.values\n",
    "\n",
    "# Try 2 to 6 clusters\n",
    "for n_clusters in range(2, 7):\n",
    "    # Fit KMeans model and calculate silhouette score\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    score = silhouette_score(X, labels)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Silhouette score for {n_clusters} clusters: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df428e",
   "metadata": {},
   "source": [
    "### 2.2 Cluster using PCA-transformed data (2 marks)\n",
    "\n",
    "Implement Kmeans clustering using the PCA-transformed data. Compare the silhouette scores using 2, 3, 4, 5 and 6 clusters and 2, 3, 4, 5 and 6 principle components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0a5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement clustering with PCA-transformed data using cluster_fn above\n",
    "\n",
    "def cluster_fn_pca(n_clusters, n_components, X):\n",
    "    '''Calculate silhouette score for a given dataset, number of clusters, \n",
    "       and number of principle components using Kmeans clustering (random_state=0)\n",
    "        \n",
    "        n_clusters (int): number of clusters to use for Kmeans\n",
    "        n_components (int): number of principle components\n",
    "        X (numpy.array or pandas.DataFrame): unlabelled dataset\n",
    "        \n",
    "        returns: silhouette score\n",
    "    '''\n",
    "    # Apply PCA to reduce dimensionality\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    # Cluster the data using KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(X_pca)\n",
    "    \n",
    "    # Calculate the silhouette score\n",
    "    score = silhouette_score(X_pca, labels)\n",
    "    \n",
    "    return score\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for n_clusters in range(2, 7):\n",
    "    scores[n_clusters] = {}\n",
    "    for n_components in range(2, 7):\n",
    "        score = cluster_fn_pca(n_clusters, n_components, X)\n",
    "        scores[n_clusters][n_components] = score\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb5219",
   "metadata": {},
   "source": [
    "### 2.3 Display results (2 marks)\n",
    "\n",
    "Print the results for 2.1 and 2.2 in a table. Include column and row labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae81ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Raw data  PCA (2 components)  PCA (3 components)  \\\n",
      "Number of clusters                                                     \n",
      "2                   0.584013            0.619442            0.611625   \n",
      "3                   0.561640            0.599961            0.586609   \n",
      "4                   0.543411            0.589955            0.570949   \n",
      "5                   0.508064            0.587472            0.567470   \n",
      "6                   0.510399            0.585963            0.564725   \n",
      "\n",
      "                    PCA (4 components)  PCA (5 components)  \n",
      "Number of clusters                                          \n",
      "2                             0.600752            0.567088  \n",
      "3                             0.570531            0.545911  \n",
      "4                             0.553715            0.521348  \n",
      "5                             0.549286            0.515809  \n",
      "6                             0.546752            0.512537  \n"
     ]
    }
   ],
   "source": [
    "# TODO: Display results\n",
    "import pandas as pd\n",
    "\n",
    "# Results for raw data clustering\n",
    "raw_data_scores = {}\n",
    "for n_clusters in range(2, 7):\n",
    "    score = cluster_fn(n_clusters, X)\n",
    "    raw_data_scores[n_clusters] = score\n",
    "    \n",
    "# Results for PCA-transformed data clustering\n",
    "pca_scores = {}\n",
    "for n_clusters in range(2, 7):\n",
    "    pca_scores[n_clusters] = {}\n",
    "    for n_components in range(2, 7):\n",
    "        score = cluster_fn_pca(n_clusters, n_components, X)\n",
    "        pca_scores[n_clusters][n_components] = score\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "df = pd.DataFrame({\n",
    "    'Raw data': raw_data_scores,\n",
    "    'PCA (2 components)': pca_scores[2],\n",
    "    'PCA (3 components)': pca_scores[3],\n",
    "    'PCA (4 components)': pca_scores[4],\n",
    "    'PCA (5 components)': pca_scores[5],\n",
    "})\n",
    "\n",
    "# Rename the index to reflect the number of clusters\n",
    "df.index.name = 'Number of clusters'\n",
    "\n",
    "# Print the results\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1086de9",
   "metadata": {},
   "source": [
    "**Question**: Which combination of number of clusters and number of components produced the best results? What is the silhouette score for this combination? **(3 marks)**\n",
    "\n",
    "*Based on the table, it appears that the combination of 2 clusters and 2 PCA components produced the best result with a silhouette score of 0.619.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e64bf4a",
   "metadata": {},
   "source": [
    "## 3. Improve results (Bonus - 3 marks)\n",
    "\n",
    "Think about how you could improve the results from the previous section. Two potential methods include preprocessing the data or selecting a different clustering algorithm. Repeat section 2 with your selected improvement method to determine what the new silhouette scores would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a8a9432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon      0.1  0.5  1.0\n",
      "Min samples               \n",
      "2             -1   -1   -1\n",
      "5             -1   -1   -1\n",
      "10            -1   -1   -1\n",
      "Best parameters: eps=0.1, min_samples=2\n",
      "Best silhouette score: -1.000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Repeat steps 2.1-2.3 using a different method/preprocessing/etc.\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def cluster_fn_dbscan(eps, min_samples, X):\n",
    "    '''Calculate silhouette score for a given dataset, epsilon,\n",
    "    and minimum number of samples using DBSCAN clustering\n",
    "    eps (float): maximum distance between two samples for them to be considered as in the same neighborhood\n",
    "    min_samples (int): minimum number of samples required for a cluster\n",
    "    X (numpy.array or pandas.DataFrame): unlabelled dataset\n",
    "    \n",
    "    returns: silhouette score\n",
    "\n",
    "    '''\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Cluster the data using DBSCAN\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "    # Calculate the silhouette score\n",
    "    if len(set(labels)) > 1:\n",
    "        score = silhouette_score(X_scaled, labels)\n",
    "    else:\n",
    "        score = -1\n",
    "\n",
    "    return score\n",
    "\n",
    "#Test different combinations of parameters\n",
    "scores_dbscan = {}\n",
    "for eps in [0.1, 0.5, 1]:\n",
    "    scores_dbscan[eps] = {}\n",
    "    for min_samples in [2, 5, 10]:\n",
    "        score = cluster_fn_dbscan(eps, min_samples, X)\n",
    "        scores_dbscan[eps][min_samples] = score\n",
    "\n",
    "#Print results in a table\n",
    "import pandas as pd\n",
    "df_scores_dbscan = pd.DataFrame(scores_dbscan)\n",
    "df_scores_dbscan.index.name = 'Min samples'\n",
    "df_scores_dbscan.columns.name = 'Epsilon'\n",
    "print(df_scores_dbscan)\n",
    "\n",
    "best_params = (max(scores_dbscan, key=lambda x: max(scores_dbscan[x].values())),\n",
    "               max(scores_dbscan[max(scores_dbscan, key=lambda x: max(scores_dbscan[x].values()))], key=scores_dbscan[max(scores_dbscan, key=lambda x: max(scores_dbscan[x].values()))].get))\n",
    "best_score = scores_dbscan[best_params[0]][best_params[1]]\n",
    "print(f\"Best parameters: eps={best_params[0]}, min_samples={best_params[1]}\")\n",
    "print(f\"Best silhouette score: {best_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4193d4",
   "metadata": {},
   "source": [
    "**Question**: Why did you select this improvement method? Which combination of number of clusters and number of components produced the best results? Did you improve the silhouette scores? If yes, how much of an improvement did you get over the previous results?\n",
    "\n",
    "*I selected this method because it can handle datasets with varying densities and noise, and can potentially identify clusters. It seems like the DBSCAN clustering did not produce any clusters for any of the combinations of eps and min_samples, as all silhouette scores are -1. This could be due to the data not being suitable for DBSCAN clustering or the chosen parameter values being suboptimal.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05128594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
